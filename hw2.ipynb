{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 作业"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本次作业主要涉及两种参数估计方法(MLE+MCMC)和强化学习(dynamic programming+Sarsa)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 参数估计之MLE\n",
    "* 采用`exampledata.txt`的数据"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 请使用example.txt。一共有3000个试次, 每一行是一个试次的数据\n",
    "* 其中1-3列分别是：\n",
    "- coherence(运动序列。共5种coherence[0.032, 0.064, 0.128, 0.256, 0.52])\n",
    "- response time (总反应时长)\n",
    "- correct(1, 正确; 0, 错误)\n",
    "* example.txt的形状为(3000, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load  data\n",
    "import numpy as np\n",
    "\n",
    "data = np.loadtxt('example.txt')\n",
    "nTrial = data.shape[0] # how many trials\n",
    "eps = np.finfo(float).eps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###\n",
    "\n",
    "**Q1.1: 请写出ddm的负对数似然函数`negloglikeli`(negative log-likelihood function)**\n",
    "\n",
    "* 请利用ddm的函数`ddmpdf`\n",
    "\n",
    "\n",
    "`def ddmpdf(k, a, B, ndt, coh, correct, rt):`\n",
    "\n",
    "* 该函数接受七个参数, 其中四个是ddm的参数\n",
    "    \n",
    "  - k: drift rate\n",
    "  - a: initial bias,范围是(0,1)\n",
    "  - B: decision boundary\n",
    "  - ndt: non-decision time\n",
    "   \n",
    "* 另外三个是一个trial的数据\n",
    "  - coh: coherence\n",
    "  - correct: correct 1 or not 0\n",
    "  - rt: reaction time in secs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ddm import ddmpdf\n",
    "import numpy as np\n",
    "eps = np.finfo(float).eps\n",
    "# define a negative log-likelihood objective function\n",
    "def negloglikeli(params, data):\n",
    "    '''\n",
    "    <params>:(4,) array, drift rate, decision boundary, initial bias, non-decision time\n",
    "    '''\n",
    "    k = params[0] # drift rate\n",
    "    B = params[1] # decision boundary\n",
    "    a = params[2] # initial bias (0, 1)\n",
    "    ndt = params[3] # non-decision time\n",
    "    \n",
    "    nTrial = data.shape[0] # trial数量\n",
    "    pp = np.empty(nTrial)\n",
    "    for i in range(nTrial): \n",
    "\n",
    "    return  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###\n",
    "\n",
    "**Q1.2: 利用最大似然估计(maximum likelihood estimation)的方法求解ddm模型参数k,B,a,ndt**\n",
    "\n",
    "参数k,B,a,ndt的bounds分别为((0, 20), (0, 5), (0, 1), (0, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "print('\\nfitted drift coefficient is ', res.x[0])\n",
    "print('fitted decision boundary is ', res.x[1])\n",
    "print('fitted initial bias is ', res.x[2])\n",
    "print('fitted nondecision time is ', res.x[3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正确答案如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 参数估计之MCMC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###\n",
    "**Q2: 利用Metropolitan-Hasting的方法估计DDM模型中的参数：drift rate(k) .不能借助工具包，必须手写M-H**\n",
    "* 请使用example.txt。\n",
    "* 将DDM中其余参数固定为： \n",
    "    - B(boundary) = 2\n",
    "    - a(initial bias) = 0.5\n",
    "    - ndt(non-decision time) = 0.1\n",
    "* (代码中已经固定randomseed，每一次结果都将一致。请勿修改)\n",
    "* hint：\n",
    "    - 提议分布建议使用正态分布。正态分布可以使用scipy.stats.norm()\n",
    "    - 从提议分布中每一次采样，起始值都设置为每一次循环初始的initial值\n",
    "    - 从提议分布中采样的结果通过exp()转换（因为drift rate始终大于零）\n",
    "    - $\\min[\\frac{f(x)}{f(y)}, 1] $ 可以被表示为 $\\min[\\log(f(x))-\\log(f(y)), 0]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先写好loglikehood func（不用取负值）\n",
    "import numpy as np\n",
    "from ddm import ddmpdf\n",
    "\n",
    "def loglikeli(k, data):\n",
    "    '''\n",
    "    共有四个参数。其中：\n",
    "    <k>:    drift rate\n",
    "    <B>:    decision boundary\n",
    "    <a>:    initial bias\n",
    "    <ndt>:  non-decision time\n",
    "    <data>: 输入的数据。来自example.txt\n",
    "    注意:除了k以外的剩下三个参数(B,a,ndt)均已被固定\n",
    "    '''\n",
    "    B = 2 # decision boundary\n",
    "    a = 0.5# initial bias (0, 1)\n",
    "    ndt = 0.1 # non-decision time\n",
    "    nTrial = data.shape[0] # how many trials\n",
    "    pp = np.empty(nTrial)\n",
    "    for i in range(nTrial): # loop trial\n",
    "   \n",
    "    return  # take log, sum，add negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm, uniform\n",
    "import numpy as np\n",
    "\n",
    "#proposal dist 为gamma分布.使得drift rate始终大于零\n",
    "def metropolis_hastings(data, y_k, n_sample=3000, n_burnin=1000, random_seed=1234):\n",
    "    '''\n",
    "    <data>:         需要加载的数据,example.txt\n",
    "    <y_k>:          先初始化一个k\n",
    "    <n_sample>:     需要采样的次数\n",
    "    <n_burin>:      需要被丢弃的采样数量\n",
    "    <randomseed>:   随机种子。用于重现结果\n",
    "    \n",
    "    '''\n",
    "    np.random.seed(random_seed)\n",
    "    samples = []\n",
    "\n",
    "    return samples\n",
    "\n",
    "# 设置初始参数值\n",
    "y_k = 0.1\n",
    "\n",
    "# 调用 Metropolis-Hastings 算法\n",
    "samples = metropolis_hastings(data, y_k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize = (6,4))\n",
    "plt.hist(samples, bins=15, density=True, label='samples')\n",
    "plt.xlabel('drift rate')\n",
    "plt.xlim(0.6)\n",
    "plt.xticks([0.6,0.7,0.8,0.9,1.0,1.1])\n",
    "plt.ylabel('Density')\n",
    "plt.title(' Estimation of Samples')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正确答案近似下图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 强化学习之dynamic programming"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \n",
    "我们接下来的游戏需要借助一个冰湖任务完成。这个游戏的规则很简单：掉进蓝色冰窟窿内即失败(游戏结束)；顺利到达goal(G)即成功(游戏结束)。\n",
    "在这个冰湖环境中，agent的动作为：\n",
    "* 0: 上\n",
    "* 1: 下\n",
    "* 2: 左\n",
    "* 3: 右\n",
    "##### 先来看看我们已经拥有的冰湖任务的环境。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.env import frozen_lake\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "seed = 1234\n",
    "env = frozen_lake(seed=seed)\n",
    "env.reset()\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4, 4))\n",
    "env.render(ax)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###\n",
    "**Q3：完成value iteration。**\n",
    "完成value iteration的步骤(伪代码)：\n",
    "\n",
    "1. 输入一个初始policy $(\\pi)$\n",
    "2. 输入一个极小值 $\\theta >0$ \n",
    "3. 为除了终点的所有状态$(s)设置初始值V(s)$\n",
    "4. 循环\n",
    "    1. $ \\Delta  ← 0$\n",
    "    2. 遍历每一个状态空间 s ∈ States\n",
    "        1. $ v ← V(s)$\n",
    "        2. $ V(s) ← \\max\\limits_{a} \\sum\\limits_{s'} p(s'|s, a) * [R(s') + \\gamma * V(s')]$\n",
    "        3. $\\Delta ← \\max(\\Delta , |v - V(s)|)$\n",
    "- 直到 $\\Delta  < \\theta$，停止循环\n",
    "5. $ \\pi(s) = \\argmax\\limits_{a}\\sum\\limits_{s'} p(s'|s, a) * [R(s') + \\gamma * V(s')]$\n",
    "6. 返回 $V,\\pi$\n",
    "    \n",
    "hint：\n",
    "* 可以使用`env.r()`获取下一个状态的reward\n",
    "* 可以使用`env.p_s_next()`来获取状态转移概率\n",
    "* 可以借助`np.eye()`来找到能返回最大值的action\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "from utils.viz import viz \n",
    "viz.get_style()\n",
    "\n",
    "def value_iter(env, seed=1234, theta=1e-4, gamma=.99, show_update=False):\n",
    "    '''\n",
    "    <env>:   冰湖环境\n",
    "    <seed>:  随机种子\n",
    "    <theta>: 极小值，用于和Δ比较，判断收敛\n",
    "    <gamma>: 折扣因子\n",
    "    <show_update>: 更新过程的展示（默认为否，我们直接看结果即可）\n",
    "    '''\n",
    "    rng = np.random.RandomState(seed)\n",
    "    # 任意初始化 V(s), 但 V(terminal)=0\n",
    "    V = rng.rand(env.nS) * 0.001\n",
    "    # except v(terminal) = 0\n",
    "    for s in env.s_termination:\n",
    "        V[s] = 0\n",
    "    # init policy \n",
    "    pi = np.zeros([env.nS, env.nA])\n",
    "    # 循环直至收敛（delta < theta）\n",
    "    while True:\n",
    "        delta = 0\n",
    "        for s in env.S:\n",
    "            v_old = V[s].copy()\n",
    "            q = np.zeros([env.nA])\n",
    "            ##-------------------------------------------##\n",
    "            ##                   ans                     ##\n",
    "            ##-------------------------------------------##\n",
    "        # 可视化 \n",
    "        if show_update:\n",
    "            _, axs = plt.subplots(1, 2, figsize=(8, 4))\n",
    "            clear_output(True)\n",
    "            ax = axs[0]\n",
    "            env.show_v(ax, V)\n",
    "            ax = axs[1]\n",
    "            env.show_pi(ax, pi)\n",
    "            time.sleep(.1)\n",
    "            plt.show()\n",
    "\n",
    "        # 判断收敛\n",
    "        if delta < theta: break \n",
    "\n",
    "    for s in env.s_termination:\n",
    "        V[s] = 0\n",
    "    return V, pi \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from utils.viz import viz \n",
    "viz.get_style()\n",
    "\n",
    "V2, pi2 = value_iter(env)\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 4))\n",
    "ax = axs[0]\n",
    "env.show_v(ax, V2)\n",
    "ax = axs[1]\n",
    "env.show_pi(ax, pi2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正确答案近似下图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 强化学习中之 sarsa (TD-learning)\n",
    "课堂上我们讲的内容是Q-learning。SARSA和Q-learning都属于强化学习中的TD-learning范畴，因为它们都使用了时序差分学习(TD-learning)的思想来更新值函数。虽然它们的目标相同，但它们在更新策略上有一些不同之处。\n",
    "\n",
    "1. **目标**：\n",
    "   - Q-learning的目标是学习最优的状态-动作值函数Q，并根据该值函数选择动作。它基于下一状态下所有可能动作的最大值更新。\n",
    "   - SARSA的目标是学习最优的状态-动作值函数Q，并根据该值函数选择动作。它基于当前状态-动作对的值更新。\n",
    "\n",
    "2. **更新策略**：\n",
    "   - 在Q-learning中，Q值的更新考虑当前状态下采取的动作($a_t$),以及下一个状态下的最大价值$\\left(\\underset{a}{\\max}Q^{\\pi}{(s_{t+1},a)}\\right)$。具体地说，更新公式为：\n",
    "  \n",
    "      $Q^{\\pi}{(s_t,a_t)} = Q^{\\pi}{(s_t,a_t)} + \\alpha * \\left[r + \\gamma*\\underset{a}{\\max}Q^{\\pi}{(s_{t+1},a)}-Q^{\\pi}{(s_t,a_t)}\\right]$\n",
    "   - 在SARSA中，Q值的更新考虑了当前状态下采取的动作$(Q^{\\pi}{(s_t,a_t)})$以及在下一个状态下采取的动作$(Q^{\\pi}{(s_{t+1},a_{t+1})})$。具体地说，更新公式为：\n",
    "  \n",
    "      $Q^{\\pi}{(s_t,a_t)} = Q^{\\pi}{(s_t,a_t)} + \\alpha * \\left[r + \\gamma* Q^{\\pi}{(s_{t+1},a_{t+1})}-Q^{\\pi}{(s_t,a_t)}\\right]$\n",
    "   \n",
    "   - 其中，$(s_{t})$是当前状态，$(a_{t})$是当前动作，$(r)$是获得的奖励，$(s_{t+1})$是下一个状态，$(a_{t+1})$是下一个状态下采取的动作，$(\\alpha) $是学习率，$(\\gamma)$是折扣因子。\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \n",
    "**Q4：补充sarsa 代码**\n",
    "\n",
    "我们来看一下实现Sarsa的步骤：\n",
    "1. 遍历每一个episode (episode = 1 to episodes):\n",
    "    1. 初始化状态 s\n",
    "    2. 基于$Q(s, a)$，根据e-greedy policy来选择action\n",
    "    3. 循环（检测收敛）\n",
    "        1. $采取 action (a)$, $观察到 reward  (r)$  $下一个状态$ next  state $ ( s_{t+1})$\n",
    "        2. $采取下一个动作 action (a')。基于Q(s_{t+1}, a_{t+1})，根据$ e-greedy policy $来选择下一个action $\n",
    "        3. $Q(s, a) ← Q(s, a) + \\alpha * [r + \\gamma * Q(s_{t+1}, a_{t+1}) - Q(s, a)] $\n",
    "        4. $s ← s_{t+1}$    记录状态，s_next为s\n",
    "        5. $a ← a_{t+1}$    记录动作，a_next为a\n",
    "    - 直到s到达终点，停止循环\n",
    "\n",
    "2. episode loop 结束，return $Q$\n",
    "\n",
    "hint\n",
    "* episode是指训练的总次数\n",
    "*  这一步：$Q(s, a) ← Q(s, a) + \\alpha * \\left[r + \\gamma * Q(s_{t+1}, a_{t+1}) - Q(s, a)\\right]$ ，需要考虑下一个状态是否为done(终点)。如为终点，下一步$Q(s_{t+1}, a_{t+1})$不存在，写法见课堂Q-learning代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "seed = 1234\n",
    "rng = np.random.RandomState(seed)\n",
    "\n",
    "def e_greedy(q, rng, env, eps):\n",
    "    a_max = np.argwhere(q==np.max(q)).flatten()\n",
    "    policy = np.sum([np.eye(env.nA)[i] for i in a_max], axis=0) / len(a_max)\n",
    "    if rng.rand() < 1-eps:\n",
    "        a = rng.choice(env.nA, p=policy)\n",
    "    else:\n",
    "        a = rng.choice(env.nA)\n",
    "    return a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "from utils.viz import viz \n",
    "viz.get_style()\n",
    "\n",
    "def Sarsa(env, alpha=.2, eps=.1, gamma=.99, max_epi=5000, seed=1234, theta=1e-4):\n",
    "    '''\n",
    "    <env>:当前所属冰湖环境\n",
    "    <alpha>:     学习率\n",
    "    <eps>:       一个极小值,用于随机性结果判断\n",
    "    <gamma>:     折扣因子\n",
    "    <max_epi>:   最大训练次数\n",
    "    <seed>:      随机种子,确保每次结果可重现\n",
    "    <theta>:     极小值，用于和Δ比较，判断收敛\n",
    "    '''\n",
    "    rng = np.random.RandomState(seed)\n",
    "    # initialize Q\n",
    "    Q = np.zeros([env.nS, env.nA])\n",
    "    for _ in range(max_epi):\n",
    "        G = 0\n",
    "        q_old = Q.copy()\n",
    "        s, _, done = env.reset()\n",
    "        # 采样At, 观察到 Rt和 St+1\n",
    "        a = e_greedy(Q[s, :], rng, env, eps)\n",
    "        while True:\n",
    "            ##-------------------------------------------##\n",
    "            ##                   ans                     ##\n",
    "            ##-------------------------------------------##\n",
    "            if done:\n",
    "                break \n",
    "            ##-------------------------------------------##\n",
    "            ##                   ans                     ##\n",
    "            ##-------------------------------------------##            #计算delta值\n",
    "        if (delta < theta).all():\n",
    "            break\n",
    "    pi = np.eye(env.nA)[np.argmax(Q, axis=1)]\n",
    "    return Q, pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 可视化\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "from utils.viz import viz \n",
    "viz.get_style()\n",
    "\n",
    "Q_sarsa, pi_sarsa = Sarsa(env)\n",
    "V3 = Q_sarsa.max(1)\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 4))\n",
    "ax = axs[0]\n",
    "env.show_v(ax, V3)\n",
    "ax = axs[1]\n",
    "env.show_pi(ax, pi_sarsa)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正确答案近似下图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
